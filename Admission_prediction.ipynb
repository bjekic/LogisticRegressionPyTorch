{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Important Functions "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class logistic_regression(nn.Module):\n",
    "    def __init__(self,in_dim):\n",
    "        super().__init__()\n",
    "        self.log_reg = nn.Sequential(\n",
    "        nn.Linear(in_dim,1),\n",
    "        nn.Sigmoid()    \n",
    "        )\n",
    "    def forward(self,x):\n",
    "        return self.log_reg(x)\n",
    "    \n",
    "def train_log_reg(x_train, y_train, no_epochs = 100000, learn_rate = 0.1):\n",
    "    # Define the model\n",
    "    no_features = x_train.shape[1]\n",
    "    model = logistic_regression(no_features)\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr = learn_rate)\n",
    "    criterion = nn.BCELoss()\n",
    "    \n",
    "    loss_all = []\n",
    "    loss_prev = 1\n",
    "    # Train the model\n",
    "    for t in range(no_epochs):\n",
    "        y_pred = model(x_train)\n",
    "        loss = criterion(y_pred, y_train)\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        if np.abs(loss.item()-loss_prev)<1e-17:\n",
    "            break\n",
    "        \n",
    "        loss_prev = loss.item()\n",
    "        loss_all.append(loss.item())\n",
    "    \n",
    "    print('\\nLoss on training set: ' + str(loss.item()))   \n",
    "    plt.plot(loss_all)\n",
    "    plt.xlabel('Epoch')\n",
    "    plt.ylabel('Loss')\n",
    "    plt.show()    \n",
    "    return model, loss.item()\n",
    "\n",
    "# Normalize data\n",
    "def normalize_data(input_data):\n",
    "    mu = input_data.mean(axis=0)\n",
    "    std = input_data.std(axis=0)\n",
    "    return (input_data-mu)/std, mu, std\n",
    "\n",
    "# Evaluate the model\n",
    "def evaluate_model(y_pred,y_test):\n",
    "    y_output = y_pred\n",
    "    y_output[y_output>=0.5]=1\n",
    "    y_output[y_output<0.5]=0\n",
    "        \n",
    "    TP = np.sum(    y_output  *    y_test  )\n",
    "    TN = np.sum( (1-y_output) * (1-y_test) )\n",
    "    FP = np.sum(    y_output  * (1-y_test) )\n",
    "    FN = np.sum( (1-y_output) *    y_test  )\n",
    "    #print(str(TP)+' '+str(TN)+' '+str(FP)+' '+str(FN))        \n",
    "    \n",
    "    accuracy  = (TP+TN) / (TP+TN+FP+FN)\n",
    "    recall    = TP / (TP+FN)\n",
    "    precision = TP / (TP+FP)\n",
    "    f1_score  = 2 * (precision * recall) / (precision + recall)\n",
    "    print( ' -Accuracy: '  + str(accuracy)  )\n",
    "    print( ' -Precision: ' + str(precision) )\n",
    "    print( ' -Recall: '    + str(recall)    )\n",
    "    print( ' -F1 score: '  + str(f1_score)  )\n",
    "    \n",
    "# Print the parameters of the PyTorch Linear Regression model\n",
    "def print_parameters(model):\n",
    "    for name, param in model.named_parameters():\n",
    "        if name == 'log_reg.0.weight':\n",
    "            print (' -Weights: '  + str(param.data.numpy().squeeze()), end = '; ')\n",
    "        if name == 'log_reg.0.bias':\n",
    "            print (' -Bias: '  + str(param.data.numpy().squeeze()), end = '; ')\n",
    "        print()\n",
    "    print()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Loading data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['Serial No.', 'GRE Score', 'TOEFL Score', 'University Rating', 'SOP',\n",
      "       'LOR ', 'CGPA', 'Research', 'Chance of Admit '],\n",
      "      dtype='object')\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Serial No.</th>\n",
       "      <th>GRE Score</th>\n",
       "      <th>TOEFL Score</th>\n",
       "      <th>University Rating</th>\n",
       "      <th>SOP</th>\n",
       "      <th>LOR</th>\n",
       "      <th>CGPA</th>\n",
       "      <th>Research</th>\n",
       "      <th>Chance of Admit</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>337</td>\n",
       "      <td>118</td>\n",
       "      <td>4</td>\n",
       "      <td>4.5</td>\n",
       "      <td>4.5</td>\n",
       "      <td>9.65</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>324</td>\n",
       "      <td>107</td>\n",
       "      <td>4</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.5</td>\n",
       "      <td>8.87</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>316</td>\n",
       "      <td>104</td>\n",
       "      <td>3</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.5</td>\n",
       "      <td>8.00</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>322</td>\n",
       "      <td>110</td>\n",
       "      <td>3</td>\n",
       "      <td>3.5</td>\n",
       "      <td>2.5</td>\n",
       "      <td>8.67</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>314</td>\n",
       "      <td>103</td>\n",
       "      <td>2</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>8.21</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>6</td>\n",
       "      <td>330</td>\n",
       "      <td>115</td>\n",
       "      <td>5</td>\n",
       "      <td>4.5</td>\n",
       "      <td>3.0</td>\n",
       "      <td>9.34</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>7</td>\n",
       "      <td>321</td>\n",
       "      <td>109</td>\n",
       "      <td>3</td>\n",
       "      <td>3.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>8.20</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>8</td>\n",
       "      <td>308</td>\n",
       "      <td>101</td>\n",
       "      <td>2</td>\n",
       "      <td>3.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>7.90</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>9</td>\n",
       "      <td>302</td>\n",
       "      <td>102</td>\n",
       "      <td>1</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.5</td>\n",
       "      <td>8.00</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>10</td>\n",
       "      <td>323</td>\n",
       "      <td>108</td>\n",
       "      <td>3</td>\n",
       "      <td>3.5</td>\n",
       "      <td>3.0</td>\n",
       "      <td>8.60</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Serial No.  GRE Score  TOEFL Score  University Rating  SOP  LOR   CGPA  \\\n",
       "0           1        337          118                  4  4.5   4.5  9.65   \n",
       "1           2        324          107                  4  4.0   4.5  8.87   \n",
       "2           3        316          104                  3  3.0   3.5  8.00   \n",
       "3           4        322          110                  3  3.5   2.5  8.67   \n",
       "4           5        314          103                  2  2.0   3.0  8.21   \n",
       "5           6        330          115                  5  4.5   3.0  9.34   \n",
       "6           7        321          109                  3  3.0   4.0  8.20   \n",
       "7           8        308          101                  2  3.0   4.0  7.90   \n",
       "8           9        302          102                  1  2.0   1.5  8.00   \n",
       "9          10        323          108                  3  3.5   3.0  8.60   \n",
       "\n",
       "   Research  Chance of Admit   \n",
       "0         1                 1  \n",
       "1         1                 1  \n",
       "2         1                 1  \n",
       "3         1                 1  \n",
       "4         0                 1  \n",
       "5         1                 1  \n",
       "6         1                 1  \n",
       "7         0                 1  \n",
       "8         0                 0  \n",
       "9         0                 0  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Import data\n",
    "data = pd.read_csv('Admission_Predict_logits.csv')\n",
    "\n",
    "# Feature names\n",
    "print(data.columns)\n",
    "\n",
    "# Show first 10 examples\n",
    "data.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Preparing data\n",
    "x = torch.tensor(data.drop(['Serial No.', 'Chance of Admit '],axis=1).values).float()\n",
    "y = torch.tensor(data['Chance of Admit ']).float().view(-1,1)\n",
    "\n",
    "x_train_non_normalized, x_test_non_normalized, y_train, y_test = train_test_split(x, y, test_size = 0.20, random_state = 3)\n",
    "x_train, mu, std = normalize_data(x_train_non_normalized)\n",
    "x_test = ( x_test_non_normalized - mu )/std"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# PyTorch Logistic Regression model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Loss on training set: 0.24464961886405945\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training set:\n",
      " -Loss: 0.24464953\n",
      " -Accuracy: 0.9125\n",
      " -Precision: 0.9271137\n",
      " -Recall: 0.9695122\n",
      " -F1 score: 0.9478390139768242\n",
      "\n",
      "Test set:\n",
      " -Loss: 0.26002595\n",
      " -Accuracy: 0.92\n",
      " -Precision: 0.91358024\n",
      " -Recall: 0.9866667\n",
      " -F1 score: 0.9487179953659959\n"
     ]
    }
   ],
   "source": [
    "# Train the model without regularization\n",
    "model, loss = train_log_reg(x_train, y_train, learn_rate = 0.01)\n",
    "\n",
    "# Evaluate the model on train set\n",
    "y_pred_train = model(x_train)\n",
    "\n",
    "print('Training set:')\n",
    "criterion = nn.BCELoss()\n",
    "loss = criterion(y_pred_train, y_train).data.numpy().squeeze()\n",
    "print( ' -Loss: '      + str(loss) )\n",
    "evaluate_model(y_pred_train.data.numpy(), y_train.data.numpy())\n",
    "\n",
    "\n",
    "# Evaluate the model on test set\n",
    "y_pred_test = model(x_test)\n",
    "\n",
    "print('\\nTest set:')\n",
    "criterion = nn.BCELoss()\n",
    "loss = criterion(y_pred_test, y_test).data.numpy().squeeze()\n",
    "print( ' -Loss: ' + str(loss) )\n",
    "evaluate_model(y_pred_test.data.numpy(), y_test.data.numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parameters of the PyTorch model:\n",
      " -Weights: [0.35574058 0.24128066 0.06788306 0.21942492 0.33014035 2.0288944\n",
      " 0.27486914]; \n",
      " -Bias: 3.3996217; \n",
      "\n"
     ]
    }
   ],
   "source": [
    "print('Parameters of the PyTorch model:')\n",
    "print_parameters(model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Scikit-learn Logistic Regression model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training set:\n",
      " -Accuracy: 0.9125\n",
      " -Precision: 0.9271137\n",
      " -Recall: 0.9695122\n",
      " -F1 score: 0.9478390139768242\n",
      "Test set:\n",
      " -Accuracy: 0.92\n",
      " -Precision: 0.91358024\n",
      " -Recall: 0.9866667\n",
      " -F1 score: 0.9487179953659959\n"
     ]
    }
   ],
   "source": [
    "# Instantiating the model and training\n",
    "log_reg_sklearn = LogisticRegression( penalty='none' )\n",
    "log_reg_sklearn.fit(x_train, y_train.data.numpy().ravel())\n",
    "\n",
    "# Evaluating the sklearn model\n",
    "print('Training set:')\n",
    "evaluate_model( log_reg_sklearn.predict(x_train).reshape(-1,1), y_train.data.numpy() )\n",
    "\n",
    "print('Test set:')\n",
    "evaluate_model( log_reg_sklearn.predict(x_test).reshape(-1,1), y_test.data.numpy() )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parameters of the Scikit-learn model:\n",
      " -Weights: [0.35865352 0.24336895 0.07052297 0.22031169 0.33247953 2.04399319\n",
      " 0.27729448]\n",
      " -Bias: 3.42722123060512\n"
     ]
    }
   ],
   "source": [
    "print('Parameters of the Scikit-learn model:')\n",
    "print(' -Weights: ' + str( log_reg_sklearn.coef_.squeeze()) )\n",
    "print(' -Bias: ' + str( log_reg_sklearn.intercept_.squeeze()) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
