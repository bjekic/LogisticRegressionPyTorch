{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Important functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function for normalizing data\n",
    "def NormalizeData(input_data):\n",
    "    mu = input_data.mean(axis = 0)\n",
    "    std = input_data.std(axis = 0)\n",
    "    return (input_data - mu) / std, mu, std\n",
    "\n",
    "# Defining class for Multinomial Logistic Regression\n",
    "class MultinomialLogisticRegression(nn.Module):\n",
    "    def __init__(self, inputDim, outputDim):\n",
    "        super().__init__()\n",
    "        self.MultinomialLogReg = nn.Sequential(\n",
    "            nn.Linear(inputDim, outputDim),\n",
    "            nn.Softmax(dim = 1)\n",
    "        )\n",
    "        \n",
    "    def forward(self, x):\n",
    "        return self.MultinomialLogReg(x)\n",
    "    \n",
    "# Function for training the model\n",
    "def TrainModel(x_train, y_train, no_epochs, learning_rate, numClass):\n",
    "    inputDim = x_train.shape[1]\n",
    "    \n",
    "    # Defining the model\n",
    "    model = MultinomialLogisticRegression(inputDim, numClass)\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr = learning_rate)\n",
    "    \n",
    "    # Training the model\n",
    "    loss_prev = 2000\n",
    "    loss_all = []\n",
    "    for epoch in range(no_epochs):\n",
    "        y_pred = model(x_train)\n",
    "        loss = criterion(y_pred, y_train)\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        if(np.abs(loss_prev - loss.item()) < 1e-15):\n",
    "            break\n",
    "            \n",
    "        loss_prev = loss.item()\n",
    "        loss_all.append(loss.item())\n",
    "        \n",
    "    print('\\nLoss on training set: ' + str(loss.item()))\n",
    "    \n",
    "    plt.plot(loss_all)\n",
    "    plt.xlabel('Epoch')\n",
    "    plt.ylabel('Loss')\n",
    "    plt.show()\n",
    "    return model, loss.item()\n",
    "\n",
    "# Function for accuracy calculation \n",
    "def CalculateAccuracy(y_pred, y_target):\n",
    "    return np.mean(y_pred == y_target) * 100"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Loading and preparing data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>input1</th>\n",
       "      <th>input2</th>\n",
       "      <th>input3</th>\n",
       "      <th>input4</th>\n",
       "      <th>input5</th>\n",
       "      <th>input6</th>\n",
       "      <th>input7</th>\n",
       "      <th>input8</th>\n",
       "      <th>input9</th>\n",
       "      <th>input10</th>\n",
       "      <th>input11</th>\n",
       "      <th>input12</th>\n",
       "      <th>input13</th>\n",
       "      <th>input14</th>\n",
       "      <th>input15</th>\n",
       "      <th>input16</th>\n",
       "      <th>class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>47</td>\n",
       "      <td>100</td>\n",
       "      <td>27</td>\n",
       "      <td>81</td>\n",
       "      <td>57</td>\n",
       "      <td>37</td>\n",
       "      <td>26</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>23</td>\n",
       "      <td>56</td>\n",
       "      <td>53</td>\n",
       "      <td>100</td>\n",
       "      <td>90</td>\n",
       "      <td>40</td>\n",
       "      <td>98</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>89</td>\n",
       "      <td>27</td>\n",
       "      <td>100</td>\n",
       "      <td>42</td>\n",
       "      <td>75</td>\n",
       "      <td>29</td>\n",
       "      <td>45</td>\n",
       "      <td>15</td>\n",
       "      <td>15</td>\n",
       "      <td>37</td>\n",
       "      <td>0</td>\n",
       "      <td>69</td>\n",
       "      <td>2</td>\n",
       "      <td>100</td>\n",
       "      <td>6</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>57</td>\n",
       "      <td>31</td>\n",
       "      <td>68</td>\n",
       "      <td>72</td>\n",
       "      <td>90</td>\n",
       "      <td>100</td>\n",
       "      <td>100</td>\n",
       "      <td>76</td>\n",
       "      <td>75</td>\n",
       "      <td>50</td>\n",
       "      <td>51</td>\n",
       "      <td>28</td>\n",
       "      <td>25</td>\n",
       "      <td>16</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>100</td>\n",
       "      <td>7</td>\n",
       "      <td>92</td>\n",
       "      <td>5</td>\n",
       "      <td>68</td>\n",
       "      <td>19</td>\n",
       "      <td>45</td>\n",
       "      <td>86</td>\n",
       "      <td>34</td>\n",
       "      <td>100</td>\n",
       "      <td>45</td>\n",
       "      <td>74</td>\n",
       "      <td>23</td>\n",
       "      <td>67</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>67</td>\n",
       "      <td>49</td>\n",
       "      <td>83</td>\n",
       "      <td>100</td>\n",
       "      <td>100</td>\n",
       "      <td>81</td>\n",
       "      <td>80</td>\n",
       "      <td>60</td>\n",
       "      <td>60</td>\n",
       "      <td>40</td>\n",
       "      <td>40</td>\n",
       "      <td>33</td>\n",
       "      <td>20</td>\n",
       "      <td>47</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   input1  input2  input3  input4  input5  input6  input7  input8  input9  \\\n",
       "0      47     100      27      81      57      37      26       0       0   \n",
       "1       0      89      27     100      42      75      29      45      15   \n",
       "2       0      57      31      68      72      90     100     100      76   \n",
       "3       0     100       7      92       5      68      19      45      86   \n",
       "4       0      67      49      83     100     100      81      80      60   \n",
       "\n",
       "   input10  input11  input12  input13  input14  input15  input16  class  \n",
       "0       23       56       53      100       90       40       98      8  \n",
       "1       15       37        0       69        2      100        6      2  \n",
       "2       75       50       51       28       25       16        0      1  \n",
       "3       34      100       45       74       23       67        0      4  \n",
       "4       60       40       40       33       20       47        0      1  "
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Import data\n",
    "data = pd.read_csv('dataset_32_pendigits.csv')\n",
    "\n",
    "# Print first 5 examples\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prepare data\n",
    "x = torch.tensor(data.drop('class', axis = 1).values).float()\n",
    "y = torch.tensor(data['class'].values)\n",
    "\n",
    "num_class = len(np.unique(y.data.numpy()))\n",
    "\n",
    "x_train, x_test, y_train, y_test = train_test_split(x, y, test_size = 0.10, random_state = 15)\n",
    "\n",
    "# Normalize data\n",
    "x_train, mu, std = NormalizeData(x_train)\n",
    "x_test = (x_test - mu) / std"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Multinomial Logistic Regression using PyTorch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Loss on training set: 1.51838219165802\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Train the model\n",
    "no_epochs = 10000\n",
    "learning_rate = 0.02\n",
    "\n",
    "model, loss = TrainModel(x_train, y_train, no_epochs, learning_rate, num_class)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy on train set: 94.50060655074807%\n",
      "Accuracy on test set: 93.45454545454545%\n"
     ]
    }
   ],
   "source": [
    "# Results\n",
    "y_pred_train = model(x_train)\n",
    "y_pred_train_np = y_pred_train.argmax(axis = 1).data.numpy()\n",
    "accuracy_train = CalculateAccuracy(y_pred_train_np, y_train.data.numpy())\n",
    "print('Accuracy on train set: ' + str(accuracy_train) + '%')\n",
    "\n",
    "y_pred_test = model(x_test)\n",
    "y_pred_test_np = y_pred_test.argmax(axis = 1).data.numpy()\n",
    "accuracy_test = CalculateAccuracy(y_pred_test_np, y_test.data.numpy())\n",
    "print('Accuracy on test set: ' + str(accuracy_test) + '%')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Multinomial Logistic Regression using sklearn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy on train set: 96.05742013748484%\n",
      "Accuracy on test set: 95.36363636363636%\n"
     ]
    }
   ],
   "source": [
    "multinomLogReg_sklearn = LogisticRegression(penalty = 'none', multi_class = 'multinomial', max_iter = 10000, tol = 1e-15)\n",
    "multinomLogReg_sklearn.fit(x_train, y_train.data.numpy().ravel())\n",
    "\n",
    "# Training data\n",
    "y_pred_sklearn_train = multinomLogReg_sklearn.predict(x_train)\n",
    "accuracy_train = CalculateAccuracy(y_pred_sklearn_train, y_train.data.numpy())\n",
    "print('Accuracy on train set: ' + str(accuracy_train) + '%')\n",
    "\n",
    "# Test data\n",
    "y_pred_sklearn_test = multinomLogReg_sklearn.predict(x_test)\n",
    "accuracy_test = CalculateAccuracy(y_pred_sklearn_test, y_test.data.numpy())\n",
    "print('Accuracy on test set: ' + str(accuracy_test) + '%')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
